{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from sensitivity_specificity_accuracy_fscore_AUC.ipynb\n",
      "Importing Jupyter notebook from UPDATE_pBest.ipynb\n",
      "Importing Jupyter notebook from UPDATE_ARCHIVE.ipynb\n",
      "Importing Jupyter notebook from UPDATE_VELOCITY_POSITION.ipynb\n",
      "Importing Jupyter notebook from CROWDING.ipynb\n",
      "Importing Jupyter notebook from init_NONDOMINATED_SOLUTION.ipynb\n",
      "Importing Jupyter notebook from store_pBest.ipynb\n",
      "Importing Jupyter notebook from PARTICLE_FITNESS.ipynb\n",
      "Importing Jupyter notebook from init_VELOCITY.ipynb\n",
      "Importing Jupyter notebook from init_PARTICLE_VALUES.ipynb\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#                  IMPLEMENTATION OF MULTI-OBJECTIVE PARTICLE SWARM OPTIMIZATION\n",
    "#                  -------------------------------------------------------------                  \n",
    "#\n",
    "#\n",
    "## This is the Main Function to execute the MOPSO Process\n",
    "\n",
    "\n",
    "import nbimporter\n",
    "import random\n",
    "from math import *\n",
    "import numpy\n",
    "import copy\n",
    "import init_VELOCITY as initvelo\n",
    "import init_PARTICLE_VALUES as initparval\n",
    "import PARTICLE_FITNESS\n",
    "import store_pBest\n",
    "import init_NONDOMINATED_SOLUTION\n",
    "import CROWDING\n",
    "import UPDATE_VELOCITY_POSITION\n",
    "import UPDATE_ARCHIVE\n",
    "import UPDATE_pBest\n",
    "import sensitivity_specificity_accuracy_fscore_AUC\n",
    "reload(sensitivity_specificity_accuracy_fscore_AUC)\n",
    "reload(UPDATE_pBest)\n",
    "reload(UPDATE_ARCHIVE)\n",
    "reload(UPDATE_VELOCITY_POSITION)\n",
    "reload(CROWDING)\n",
    "reload(init_NONDOMINATED_SOLUTION)\n",
    "reload(store_pBest)\n",
    "reload(PARTICLE_FITNESS)\n",
    "reload(initvelo)\n",
    "reload(initparval)\n",
    "\n",
    "\n",
    "# main function\n",
    "\n",
    "if __name__=='__main__':\n",
    "    normal_count=0         # Counts the number of Normal samples to be considered for individual gene\n",
    "    tumor_count=0          # Counts the number of Tumor samples to be considered for individual gene\n",
    "    with open(\"/home/sukanya/Desktop/PSO_and_MOPSO/PSO1/datasets/child.txt\") as fp:\n",
    "        for line in fp:\n",
    "            if(line.startswith(\"normal\")):\n",
    "                normal_count+=1\n",
    "            elif(line.startswith(\"tumor\")):\n",
    "                tumor_count+=1\n",
    "       \n",
    "    COUNT=normal_count+tumor_count        # total number of samples for each gene\n",
    "    SWARM_SIZE=25                         # total number of particles in the population\n",
    "    no_of_obj_func=3                      # total number of objective functions considered\n",
    "    Iteration=100\n",
    "    archive_size=25                       # set maximum capacity of archive\n",
    "    no_of_nondom_sol=0                    # Initial number of nondominated solutions in archive\n",
    "    \n",
    "    PARTICLE_VAL=initparval.initialise_PARTICLE_VALUES(COUNT,SWARM_SIZE) # initialise position values of particles in population \n",
    "    PARTICLE_FIT=[[[] for j in range(no_of_obj_func)] for i in range(SWARM_SIZE)]  # fitness values of particles in population\n",
    "    \n",
    "    ARCHIVE_VAL=[[[]for j in range(COUNT)] for i in range(archive_size)]  #position values of particles in archive\n",
    "    ARCHIVE_FIT=[[[]for j in range(no_of_obj_func)]for i in range(archive_size)]  #fitness values of particles in archive\n",
    "    \n",
    "    VELOCITY=initvelo.initialise_velocity(COUNT,SWARM_SIZE)  # initialise velocity of particle in population\n",
    "    \n",
    "    pBestPosition=[[[]for j in range(COUNT)]for i in range(SWARM_SIZE)] # personal best position for each particle in population\n",
    "    pBestFitness=[[[]for j in range(no_of_obj_func)]for i in range(SWARM_SIZE)]  # personal fitness for each particle in population\n",
    "    \n",
    "#     PARTICLE_FITNESS.update_particle(PARTICLE_FIT,no_of_obj_func,SWARM_SIZE) # update fitness values of each particle in population\n",
    "    \n",
    "    store_pBest.p_Best(pBestPosition,pBestFitness,PARTICLE_VAL,PARTICLE_FIT,SWARM_SIZE,no_of_obj_func,COUNT) # Store initial personal bests (both variable and fitness values) of particles\n",
    "   \n",
    "    \n",
    "    # the output is written in the file MOPSO_OUTPUT.txt\n",
    "    with open(\"/home/sukanya/Desktop/PSO_and_MOPSO/MOPSO/MOPSO_OUTPUT.txt\",\"w+\") as am:\n",
    "        for t in range(Iteration):\n",
    "            # Compute new fitness values for each particle in the population\n",
    "            PARTICLE_FITNESS.update_particle(PARTICLE_FIT,no_of_obj_func,SWARM_SIZE)\n",
    "            # insert nondominated particles in archive from population\n",
    "            no_of_nondom_sol=init_NONDOMINATED_SOLUTION.initialise_nondom_sol(no_of_nondom_sol,SWARM_SIZE,ARCHIVE_VAL,ARCHIVE_FIT,PARTICLE_VAL,PARTICLE_FIT,no_of_obj_func,archive_size,COUNT)\n",
    "            \n",
    "            if(no_of_nondom_sol>2):\n",
    "                no_of_nondom_sol=CROWDING.crowding_distance(no_of_nondom_sol,no_of_obj_func,COUNT,ARCHIVE_FIT,ARCHIVE_VAL)\n",
    "            # Compute new velocity and position of each particle in the population\n",
    "            no_of_nondom_sol=UPDATE_VELOCITY_POSITION.update_velocity_position(no_of_nondom_sol,SWARM_SIZE,COUNT,VELOCITY,pBestPosition,PARTICLE_VAL,ARCHIVE_VAL)\n",
    "\n",
    "            # insert new non dominated particles in archive from population\n",
    "            no_of_nondom_sol=UPDATE_ARCHIVE.update_archive(SWARM_SIZE,no_of_nondom_sol,archive_size,COUNT,ARCHIVE_VAL,PARTICLE_VAL,ARCHIVE_FIT,PARTICLE_FIT,no_of_obj_func)\n",
    "            \n",
    "            # update personal best for each particle in population\n",
    "            UPDATE_pBest.update_pBest(SWARM_SIZE,no_of_obj_func,PARTICLE_FIT,pBestFitness,COUNT,pBestPosition,PARTICLE_VAL)\n",
    "            \n",
    "            NONDOM_PARTICLE=[int(0) for i in range(no_of_nondom_sol)]\n",
    "            \n",
    "            print (str(t))\n",
    "            am.write(\"SIZE OF PARETO SET : \")\n",
    "            am.write(str(no_of_nondom_sol))\n",
    "            am.write(\"\\n\\n\")\n",
    "            am.write(\"ELEMENTS OF PARETO SET : \")\n",
    "            for  i in range(no_of_nondom_sol):\n",
    "                for j in range(SWARM_SIZE):\n",
    "                    if(ARCHIVE_FIT[i][0]==PARTICLE_FIT[j][0]):\n",
    "                        NONDOM_PARTICLE[i]=j\n",
    "                        am.write(str(j+1))\n",
    "                am.write(\"\\t\")\n",
    "            am.write(\"\\n\\n\")\n",
    "                    \n",
    "            am.write(\"FITNESS VALUES OF PARTICLES IN THE ARCHIVE : \")\n",
    "            am.write(\"\\n\\n\")\n",
    "            am.write(\"WEIGHTED T SCORE VALUES : \")\n",
    "            for j in range(no_of_nondom_sol):\n",
    "                am.write(str(ARCHIVE_FIT[j][0]))\n",
    "                am.write(\"\\t\\t\")\n",
    "            am.write(\"\\n\\n\")\n",
    "            am.write(\"WEIGHTED Z SCORE VALUES : \")\n",
    "            for j in range(no_of_nondom_sol):\n",
    "                am.write(str(ARCHIVE_FIT[j][1]))\n",
    "                am.write(\"\\t\\t\")\n",
    "            am.write(\"\\n\\n\")\n",
    "            am.write(\"INTERACTION SCORE VALUES : \")\n",
    "            for j in range(no_of_nondom_sol):\n",
    "                am.write(str(ARCHIVE_FIT[j][2]))\n",
    "                am.write(\"\\t\\t\")\n",
    "            am.write(\"\\n\")\n",
    "            am.write(\"\\n\")\n",
    "            am.write(\"**********************************************************************************************\")    \n",
    "            am.write(\"\\n\\n\")\n",
    "            \n",
    "            temp_nondom=no_of_nondom_sol\n",
    "            # reset number of nondominated particles, archive values and fitnesses to store values for next iteration\n",
    "            no_of_nondom_sol=0\n",
    "            \n",
    "            ARCHIVE_VAL=[[[]for j in range(COUNT)] for i in range(archive_size)]\n",
    "            ARCHIVE_FIT=[[[]for j in range(no_of_obj_func)]for i in range(archive_size)]\n",
    "    \n",
    "    # store the sensitivity , specificity , accuracy , f_score and area under curve value of the final non-dominated particles on archive\n",
    "    VALUES_1=[[float(0.0) for j in range(5)] for i in range(temp_nondom)]\n",
    "    with open(\"/home/sukanya/Desktop/PSO_and_MOPSO/MOPSO/Output.txt\" , \"w+\") as sn:\n",
    "        sensitivity_specificity_accuracy_fscore_AUC.values(SWARM_SIZE,NONDOM_PARTICLE,temp_nondom,VALUES_1) # calculation of the corresponding values\n",
    "\n",
    "        sn.write(\"ELEMENTS OF PARETO SET : \")\n",
    "        for i in range(temp_nondom):\n",
    "            sn.write(str(NONDOM_PARTICLE[i]+1))\n",
    "            sn.write(\"\\t\")\n",
    "        sn.write(\"\\n\\n\")\n",
    "        sn.write(\"SENSITIVITY SCORE : \")\n",
    "        for i in range(temp_nondom):\n",
    "            sn.write(str(VALUES_1[i][0]))\n",
    "            sn.write(\"\\t\")\n",
    "        sn.write(\"\\n\\n\")\n",
    "        sn.write(\"SPECIFICITY SCORE : \")\n",
    "        for i in range(temp_nondom):\n",
    "            sn.write(str(VALUES_1[i][1]))\n",
    "            sn.write(\"\\t\")\n",
    "        sn.write(\"\\n\\n\")\n",
    "        sn.write(\"ACCURACY MEASURE : \")\n",
    "        for i in range(temp_nondom):\n",
    "            sn.write(str(VALUES_1[i][2]))\n",
    "            sn.write(\"\\t\")\n",
    "        sn.write(\"\\n\\n\")\n",
    "        sn.write(\"F SCORE : \")\n",
    "        for i in range(temp_nondom):\n",
    "            sn.write(str(VALUES_1[i][3]))\n",
    "            sn.write(\"\\t\")\n",
    "        sn.write(\"\\n\\n\")\n",
    "        sn.write(\"AREA UNDER CURVE : \")\n",
    "        for i in range(temp_nondom):\n",
    "            sn.write(str(VALUES_1[i][4]))\n",
    "            sn.write(\"\\t\")\n",
    "        sn.write(\"\\n\\n\")\n",
    "            \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
